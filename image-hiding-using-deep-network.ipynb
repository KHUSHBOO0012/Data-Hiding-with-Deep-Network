{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"955751e58c300b6ecbb74d2785662725aa93c4da"},"cell_type":"code","source":"import glob\nimport os\nfrom PIL import Image,ImageOps\nimport random\nimport tensorflow as tf\nimport time\nfrom datetime import datetime\nfrom os.path import join","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e940b02b6fa3d0f88ed81d504a4d4a5e8bae31c1"},"cell_type":"code","source":"TRAIN_PATH = '../input/midimagedata/test2017/test2017/'\nLOGS_Path = \"./logs/\"\nCHECKPOINTS_PATH = './checkpoints/'\n\n\nBATCH_SIZE = 8\nLEARNING_RATE = .0001\nBETA = .75\n\nEXP_NAME = f\"beta_{BETA}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f42ac022b9dbb863fd0a33a94effa2b9a0de94e3"},"cell_type":"code","source":"files_list = glob.glob(join('../input/midimagedata/test2017/test2017/*'))\nlen(files_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f189499b977a41c78a3e01cd707aec73fa64eef"},"cell_type":"code","source":"def normalize_batch(imgs):\n    return (imgs -  np.array([0.485, 0.456, 0.406])) /np.array([0.229, 0.224, 0.225])\n                                                        \ndef denormalize_batch(imgs,should_clip=True):\n    imgs= (imgs * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n    \n    if should_clip:\n        imgs= np.clip(imgs,0,1)\n    return imgs\n\ndef get_img_batch(files_list,batch_size=4,size=(224,224),should_normalise=True):\n   \n    batch_cover = []\n    batch_secret = []\n\n    for i in range(batch_size):\n        img_secret_path = random.choice(files_list)\n        img_cover_path = random.choice(files_list)\n        \n        img_secret = Image.open(img_secret_path).convert(\"RGB\")\n        img_cover = Image.open(img_cover_path).convert(\"RGB\")\n\n        img_secret = np.array(ImageOps.fit(img_secret,size),dtype=np.float32)\n        img_cover = np.array(ImageOps.fit(img_cover,size),dtype=np.float32)\n        \n        img_secret /= 255.\n        img_cover /= 255.\n        \n        batch_cover.append(img_cover)\n        batch_secret.append(img_secret)\n        \n    batch_cover,batch_secret = np.array(batch_cover) , np.array(batch_secret)\n    \n    if should_normalise:\n        batch_cover = normalize_batch(batch_cover)\n        batch_secret = normalize_batch(batch_secret)\n\n    return batch_cover,batch_secret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2be3eafb70ad5fe51a413aaa5e2718b748f234f"},"cell_type":"code","source":"def get_prep_network_op(secret_tensor):\n    \n    with tf.variable_scope('prep_net'):\n        \n        with tf.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.layers.conv2d(inputs=secret_tensor,filters=50,kernel_size=3,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"2\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        with tf.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.layers.conv2d(inputs=secret_tensor,filters=50,kernel_size=4,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"2\",activation=tf.nn.relu)           \n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"4\",activation=tf.nn.relu)\n\n        with tf.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.layers.conv2d(inputs=secret_tensor,filters=50,kernel_size=5,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"2\",activation=tf.nn.relu)           \n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        concat_1 = tf.concat([conv_3x3,conv_4x4,conv_5x5],axis=3,name='concat_1')\n        \n        conv_5x5 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=5,padding='same',name=\"final_5x5\",activation=tf.nn.relu)\n        conv_4x4 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=4,padding='same',name=\"final_4x4\",activation=tf.nn.relu)\n        conv_3x3 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=3,padding='same',name=\"final_3x3\",activation=tf.nn.relu)\n        \n        concat_final = tf.concat([conv_5x5,conv_4x4,conv_3x3],axis=3,name='concat_final')\n\n        return concat_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51075b890a038545d678d9f4cab63c6595f2c67d"},"cell_type":"code","source":"def get_hiding_network_op(cover_tensor,prep_output):\n    \n    with tf.variable_scope('hide_net'):\n        concat_input = tf.concat([cover_tensor,prep_output],axis=3,name='images_features_concat')\n        \n        with tf.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.layers.conv2d(inputs=concat_input,filters=50,kernel_size=3,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"2\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        with tf.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.layers.conv2d(inputs=concat_input,filters=50,kernel_size=4,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"2\",activation=tf.nn.relu)          \n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"4\",activation=tf.nn.relu)\n\n        with tf.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.layers.conv2d(inputs=concat_input,filters=50,kernel_size=5,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"2\",activation=tf.nn.relu)          \n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        concat_1 = tf.concat([conv_3x3,conv_4x4,conv_5x5],axis=3,name='concat_1')\n        \n        conv_5x5 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=5,padding='same',name=\"final_5x5\",activation=tf.nn.relu)\n        conv_4x4 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=4,padding='same',name=\"final_4x4\",activation=tf.nn.relu)\n        conv_3x3 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=3,padding='same',name=\"final_3x3\",activation=tf.nn.relu)\n        \n        concat_final = tf.concat([conv_5x5,conv_4x4,conv_3x3],axis=3,name='concat_final')\n        output = tf.layers.conv2d(inputs=concat_final,filters=3,kernel_size=1,padding='same',name='output')\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22795ec54317a9f6e5cc58193da2678e031d2826"},"cell_type":"code","source":"def prepare_training_graph(secret_tensor,cover_tensor,global_step_tensor):\n    \n    prep_output_op = get_prep_network_op(secret_tensor)\n    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor,prep_output=prep_output_op)\n    noise_add_op = get_noise_layer_op(hiding_output_op)\n    reveal_output_op = get_reveal_network_op(noise_add_op)\n    \n    loss_op,secret_loss_op,cover_loss_op = get_loss_op(secret_tensor,reveal_output_op,cover_tensor,hiding_output_op,beta=BETA)\n\n    minimize_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss_op,global_step=global_step_tensor)\n    \n    tf.summary.scalar('loss', loss_op,family='train')\n    tf.summary.scalar('reveal_net_loss', secret_loss_op,family='train')\n    tf.summary.scalar('cover_net_loss', cover_loss_op,family='train')\n\n    tf.summary.image('secret',get_tensor_to_img_op(secret_tensor),max_outputs=1,family='train')\n    tf.summary.image('cover',get_tensor_to_img_op(cover_tensor),max_outputs=1,family='train')\n    tf.summary.image('hidden',get_tensor_to_img_op(hiding_output_op),max_outputs=1,family='train')\n    tf.summary.image('hidden_noisy',get_tensor_to_img_op(noise_add_op),max_outputs=1,family='train')\n    tf.summary.image('revealed',get_tensor_to_img_op(reveal_output_op),max_outputs=1,family='train')\n\n    merged_summary_op = tf.summary.merge_all()\n    \n    return loss_op, minimize_op, merged_summary_op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c54080fb4c357dee245c44b465329099dee56ee"},"cell_type":"code","source":"def get_reveal_network_op(container_tensor):\n    \n    with tf.variable_scope('reveal_net'):\n        \n        with tf.variable_scope(\"3x3_conv_branch\"):\n            conv_3x3 = tf.layers.conv2d(inputs=container_tensor,filters=50,kernel_size=3,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"2\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_3x3 = tf.layers.conv2d(inputs=conv_3x3,filters=50,kernel_size=3,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        with tf.variable_scope(\"4x4_conv_branch\"):\n            conv_4x4 = tf.layers.conv2d(inputs=container_tensor,filters=50,kernel_size=4,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"2\",activation=tf.nn.relu)          \n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_4x4 = tf.layers.conv2d(inputs=conv_4x4,filters=50,kernel_size=4,padding='same',name=\"4\",activation=tf.nn.relu)\n\n        with tf.variable_scope(\"5x5_conv_branch\"):\n            conv_5x5 = tf.layers.conv2d(inputs=container_tensor,filters=50,kernel_size=5,padding='same',name=\"1\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"2\",activation=tf.nn.relu)           \n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"3\",activation=tf.nn.relu)\n            conv_5x5 = tf.layers.conv2d(inputs=conv_5x5,filters=50,kernel_size=5,padding='same',name=\"4\",activation=tf.nn.relu)\n            \n        concat_1 = tf.concat([conv_3x3,conv_4x4,conv_5x5],axis=3,name='concat_1')\n        \n        conv_5x5 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=5,padding='same',name=\"final_5x5\",activation=tf.nn.relu)\n        conv_4x4 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=4,padding='same',name=\"final_4x4\",activation=tf.nn.relu)\n        conv_3x3 = tf.layers.conv2d(inputs=concat_1,filters=50,kernel_size=3,padding='same',name=\"final_3x3\",activation=tf.nn.relu)\n        \n        concat_final = tf.concat([conv_5x5,conv_4x4,conv_3x3],axis=3,name='concat_final')\n    \n    output = tf.layers.conv2d(inputs=concat_final,filters=3,kernel_size=1,padding='same',name='output')\n\n    return output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"660b5b9d479c3a00ca1f71c41425a4ac9964a970"},"cell_type":"code","source":"def get_noise_layer_op(tensor,std=.1):\n    with tf.variable_scope(\"noise_layer\"):\n        return tensor + tf.random_normal(shape=tf.shape(tensor), mean=0.0, stddev=std, dtype=tf.float32) \n    \ndef get_loss_op(secret_true,secret_pred,cover_true,cover_pred,beta=.5):\n    \n    with tf.variable_scope(\"losses\"):\n        beta = tf.constant(beta,name=\"beta\")\n        secret_mse = tf.losses.mean_squared_error(secret_true,secret_pred)\n        cover_mse = tf.losses.mean_squared_error(cover_true,cover_pred)\n        final_loss = cover_mse + beta*secret_mse\n        return final_loss , secret_mse , cover_mse \n\ndef get_tensor_to_img_op(tensor):\n    with tf.variable_scope(\"\",reuse=True):\n        t = tensor*tf.convert_to_tensor([0.229, 0.224, 0.225]) + tf.convert_to_tensor([0.485, 0.456, 0.406])\n        return tf.clip_by_value(t,0,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b33d2d6272fc65c81ea73ad6139894e0b16af67"},"cell_type":"code","source":"def prepare_test_graph(secret_tensor,cover_tensor):\n    with tf.variable_scope(\"\",reuse=True):\n    \n        prep_output_op = get_prep_network_op(secret_tensor)\n        hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor,prep_output=prep_output_op)\n        reveal_output_op = get_reveal_network_op(hiding_output_op)\n        \n        loss_op,secret_loss_op,cover_loss_op = get_loss_op(secret_tensor,reveal_output_op,cover_tensor,hiding_output_op)\n\n        tf.summary.scalar('loss', loss_op,family='test')\n        tf.summary.scalar('reveal_net_loss', secret_loss_op,family='test')\n        tf.summary.scalar('cover_net_loss', cover_loss_op,family='test')\n\n        tf.summary.image('secret',get_tensor_to_img_op(secret_tensor),max_outputs=1,family='test')\n        tf.summary.image('cover',get_tensor_to_img_op(cover_tensor),max_outputs=1,family='test')\n        tf.summary.image('hidden',get_tensor_to_img_op(hiding_output_op),max_outputs=1,family='test')\n        tf.summary.image('revealed',get_tensor_to_img_op(reveal_output_op),max_outputs=1,family='test')\n\n        merged_summary_op = tf.summary.merge_all()\n\n        return merged_summary_op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76692924b99e2990643395461197eae4cb3d6474"},"cell_type":"code","source":"def prepare_deployment_graph(secret_tensor,cover_tensor,covered_tensor):\n    with tf.variable_scope(\"\",reuse=True):\n\n        prep_output_op = get_prep_network_op(secret_tensor)\n        hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor,prep_output=prep_output_op)\n\n        reveal_output_op = get_reveal_network_op(covered_tensor)\n\n        return hiding_output_op ,  reveal_output_op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ec8f3ef1ee3c181a21558b22850ab05f502ebaf"},"cell_type":"code","source":"tf.InteractiveSession(graph=tf.Graph()).close()\nsess = tf.InteractiveSession(graph=tf.Graph())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c46a49f20dc39d42244eecc23986b2d1a8688517"},"cell_type":"code","source":"secret_tensor = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32,name=\"input_prep\")\ncover_tensor = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32,name=\"input_hide\")\nglobal_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n\nlossout_op, train_op , summary_op = prepare_training_graph(secret_tensor,cover_tensor,global_step_tensor)\n\nwriter = tf.summary.FileWriter(\"folder_to_save_graph_3\", sess.graph)\n\ntest_op = prepare_test_graph(secret_tensor,cover_tensor)\n\ncovered_tensor = tf.placeholder(shape=[None,224,224,3],dtype=tf.float32,name=\"deploy_covered\")\ndeploy_hide_image_op , deploy_reveal_image_op = prepare_deployment_graph(secret_tensor,cover_tensor,covered_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9d8bb67c9f659cdcfa98b426f61319b422e9646"},"cell_type":"code","source":"saver = tf.train.Saver(max_to_keep=1)\nsess.run(tf.global_variables_initializer())\n# saver.restore(sess,join(CHECKPOINTS_PATH,EXP_NAME))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06477f92024557ebda071c25b4e49a1fc559ac70"},"cell_type":"code","source":"total_steps = len(files_list)//BATCH_SIZE + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69803e82e64a2c79a8fe9debc5198337fdd4dadd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fcaee6e0c50f31f5f6cd9118799a7df1057f46e"},"cell_type":"code","source":"run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\nfor ep in range(10):\n    for step in range(total_steps):\n        covers,secrets = get_img_batch(files_list=files_list,batch_size=BATCH_SIZE)\n        sess.run([train_op],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n        lossoutput=sess.run([lossout_op],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers},options=run_opts)\n        if step % 10 ==0 :\n            \n            summary,global_step = sess.run([summary_op,global_step_tensor],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n            writer.add_summary(summary,global_step)\n            \n        if step % 100 ==0 :\n            \n            covers,secrets = get_img_batch(files_list=files_list,batch_size=1)\n            summary,global_step = sess.run([test_op,global_step_tensor],feed_dict={\"input_prep:0\":secrets,\"input_hide:0\":covers})\n            writer.add_summary(summary,global_step)\n\n    print(\"after epoch %d loss is\"%(ep),lossoutput)\n    print(\"\\n\")\n    \n    save_path = saver.save(sess, join(CHECKPOINTS_PATH,EXP_NAME+\".chkp\"),global_step=global_step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b97682d863ebca6cf8455941f9c719ee6ad260b4"},"cell_type":"code","source":"# sess.close()\n\n\nwriter.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75a253c67709b63a3bc33adf3fbb4c457398b643"},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = './folder_to_save_graph_3' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8f2f55abbe10fd8b2ee8e0f3bc0938a7db741d2"},"cell_type":"code","source":"covers,secrets = get_img_batch(files_list=files_list,batch_size=1)\n\ncover = covers.squeeze()\nsecret = secrets.squeeze()\nplt.imshow(denormalize_batch(cover))\nplt.show()\nplt.imshow(denormalize_batch(secret))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9927ffbd0cca649f9cb563bb4918fd5ffe138698"},"cell_type":"code","source":"hidden = sess.run(deploy_hide_image_op,feed_dict={'input_prep:0':secrets,'input_hide:0':covers})\n\nplt.imshow(denormalize_batch(hidden.squeeze()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"319f0d5447961b6eefa172e008d71b2bc38f9fa7"},"cell_type":"code","source":"revealed = sess.run(deploy_reveal_image_op,feed_dict={'deploy_covered:0':hidden})\n\nplt.imshow(denormalize_batch(revealed.squeeze()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5c89074cf3513c3c340f29c620ac217b3dfd821"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dcbc473883273aef40f515cb42a2785f796e976"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}